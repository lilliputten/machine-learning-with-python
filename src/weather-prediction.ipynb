{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0937ee90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.19.0\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Initialize environment\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd1b1d4",
   "metadata": {},
   "source": [
    "Weather Model\n",
    "\n",
    "Taken direclty from the TensorFlow documentation (https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/HiddenMarkovModel).\n",
    "\n",
    "We will model a simple weather system and try to predict the temperature on each day given the following information.\n",
    "\n",
    "- Cold days are encoded by a 0 and hot days are encoded by a 1.\n",
    "- The first day in our sequence has an 80% chance of being cold.\n",
    "- A cold day has a 30% chance of being followed by a hot day.\n",
    "- A hot day has a 20% chance of being followed by a cold day.\n",
    "- On each day the temperature is normally distributed with mean and standard deviation 0 and 5 on a cold day and mean and standard deviation 15 and 10 on a hot day.\n",
    "\n",
    "If you're unfamiliar with standard deviation it can be put simply as the range of expected values.\n",
    "\n",
    "In this example, on a hot day the average temperature is 15 and ranges from 5 to 25.\n",
    "\n",
    "To model this in TensorFlow we will do the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9612f093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial probabilities: [0.8 0.2]\n",
      "Transition matrix: [[0.7 0.3]\n",
      " [0.2 0.8]]\n",
      "Observation means: [ 0. 15.]\n",
      "Observation stds: [ 5. 10.]\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Setting the distribution parameters using native TensorFlow Hidden Markov Models\n",
    "\n",
    "# Since TensorFlow Probability has compatibility issues, we'll implement HMM with native TF\n",
    "\n",
    "# Initial distribution: 80% chance of cold (0), 20% chance of hot (1)\n",
    "initial_probs = tf.constant([0.8, 0.2])\n",
    "\n",
    "# Transition matrix: [cold->cold, cold->hot], [hot->cold, hot->hot], former `tfd.Categorical` creation\n",
    "transition_matrix = tf.constant(\n",
    "    [\n",
    "        # Cold day: 70% stay cold, 30% become hot\n",
    "        [0.7, 0.3],\n",
    "        # Hot day: 20% become cold, 80% stay hot\n",
    "        [0.2, 0.8],\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Observation parameters: [cold_mean, hot_mean], [cold_std, hot_std]\n",
    "obs_means = tf.constant([0.0, 15.0])  # Cold: 0°, Hot: 15°, former `loc` parameter for `tfd.Normal`\n",
    "obs_stds = tf.constant(\n",
    "    [5.0, 10.0]\n",
    ")  # Cold: ±5°, Hot: ±10°, former `scale` parameter for `tfd.Normal`, not used actually\n",
    "\n",
    "print(\"Initial probabilities:\", initial_probs.numpy())\n",
    "print(\"Transition matrix:\", transition_matrix.numpy())\n",
    "print(\"Observation means:\", obs_means.numpy())\n",
    "print(\"Observation stds:\", obs_stds.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e95752",
   "metadata": {},
   "source": [
    "We've now created distribution variables to model our system and it's time to create the hidden markov model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d27bb27",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The number of steps represents the number of days that we would like to predict information for. In this case we've chosen 7, an entire week.\n",
    "\n",
    "To get the expected temperatures on each day we can do the following.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "387400ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted temperatures (HMM mean, equivalent to original TFP):\n",
      "Day 1: 3.00°C\n",
      "Day 2: 6.00°C\n",
      "Day 3: 7.50°C\n",
      "Day 4: 8.25°C\n",
      "Day 5: 8.63°C\n",
      "Day 6: 8.81°C\n",
      "Day 7: 8.91°C\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Predict expected temperatures using proper HMM mean calculation\n",
    "\n",
    "\n",
    "def predict_temperatures_hmm(num_days=7):\n",
    "    \"\"\"Calculate HMM mean like original TFP model.mean()\"\"\"\n",
    "    # This matches the original tfd.HiddenMarkovModel behavior\n",
    "    # where observation_distribution contributes to the overall mean\n",
    "\n",
    "    state_probs = initial_probs\n",
    "    expected_temps = []\n",
    "\n",
    "    for day in range(num_days):\n",
    "        # Expected observation = sum over states of (state_prob * obs_mean)\n",
    "        # This is exactly what the original observation_distribution did\n",
    "        expected_temp = tf.reduce_sum(state_probs * obs_means)\n",
    "        expected_temps.append(expected_temp.numpy())\n",
    "\n",
    "        # Forward step: update state probabilities\n",
    "        state_probs = tf.linalg.matvec(transition_matrix, state_probs, transpose_a=True)\n",
    "\n",
    "    return expected_temps\n",
    "\n",
    "\n",
    "# Predict temperatures for a week (equivalent to original model.mean())\n",
    "temperatures = predict_temperatures_hmm(7)\n",
    "print(\"\\nPredicted temperatures (HMM mean, equivalent to original TFP):\")\n",
    "for i, temp in enumerate(temperatures, 1):\n",
    "    print(f\"Day {i}: {temp:.2f}°C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab4fd36",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "\n",
    "So that's it for the core learning algorithms in TensorFlow. Hopefully you've learned about a few interesting tools that are easy to use! To practice I'd encourage you to try out some of these algorithms on different datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
